# -*- coding: utf-8 -*-
"""Credit_Card_Fraud_Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/credit-card-fraud-detection-8b43f0f5-e8d4-44f0-ab3d-4cbe9f73fd3b.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240412/auto/storage/goog4_request%26X-Goog-Date%3D20240412T194204Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D53d5f16772447e29732e4befdc6aa4dca73b1add0e6fc7267e0704422e987678633d170945e0105b7b14a207b3b474d2edb0ae0aa6110262a6bf69b66666622f8c3f75af2153a535d7176cb0d31872d66221409c82b6e74344903fcd0f2f1a4db634010ff331efd908f72b65b873c46cb721418829cc3ccf3d397660b71ff3093320d1f1151b07e1981387dac8e7cd642c079706ac12bd7f07d6a14b55d4d5e3a85cd3fb52d01843f7643c4d0fb1ef322a2e6440fcdb1f2db04bfaac54c547e8eb42f9de1f0c1ee8b73ff0ae2831e3a5002b0741c58d744fcdcec795fbd5303e940116c2ee10b46b0418cf38445bf0f8d848d2b1be3aa45ee85d6cb7685318b0
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'creditcardfraud:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F310%2F23498%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240412%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240412T194203Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D580c5bfb2d61dd6f4c890d195b1d69ecc046ca3eb5a4cec255d6550aa7593f5b7fdd62b83af744ad3e9590495c0a4160498d5c1cd208dd4c7d5d99330f55b1fc2ca1cefe58bb7155b8e3072356b680636fdf6bbc124e07dac1f6949fed6bc667fb3a5d33db9c22bb41c7d9444c942cf69dae41219cf6bc0021b235d48b7912394d1d48460e1c746b9b373459a4d01ee774ee30d274aae5d0c5221579c6ff91481aa73d483d5ae0e3b5226c8e24fefccb4a82a7fd202d9ab9c717f70028ce7ab24eae4ec31d48abb50e31d2909ff130a3313f257bbffee7df41618da39ce63f16b3f970c96cbeefcff6559dd793406166bb298d7b55bcf68971854e9adaa69648,d/jeffersonvalandro/creditcardfraud:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4213911%2F7269342%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240412%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240412T194203Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7b19054c86b14111cf0bd5ddd88b2223978b12c9e4ac64790bd66365caaa52153423c3b88226c09f17f58846ed53ac8c6c1e05977a11600749f4fbbb397b8f94dcea8b0100d9b4fcbb825856873ee271c3fae39999666b1e1af044e8b244f5914ad2ac23c9d8593dc51d31b3284c61942a85c6f2d314c7bc0fadf0fc0529d35a866580830f32f1600ad7e19843d802291054d0ea273870bf65d57b0ed67188d499d0e95e212acfd0f4ab7f7717c6f04269332209ed3ad6a1ef7f5b3157e4178b306e23005ee1c43c3d93ea93e817564dfda643b83501216c7538d4b266635fdb022a10d89fb54181e66ea757acbdb4c0a06b6eb1475207ac408ce3e94efedfda'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import os
import pandas as pd

# List files in the input directory
print("Files in input directory:", os.listdir('/kaggle/input/creditcardfraud'))

"""# Credit Card Fraud Detection

This Jupyter Notebook aims to explore and compare different machine learning models for the detection of fraudulent transactions in credit cards. Utilizing a dataset containing information about credit card transactions, including features such as time, transaction amounts, and labels indicating whether the transaction is fraudulent or not, the notebook covers the following steps:

**Exploratory Data Analysis (EDA):** Initial exploration of the dataset to understand the distribution of features, identify possible class imbalances, and comprehend the nature of the data.

**Data Preprocessing:** Handling missing values, normalizing or standardizing data, and other preprocessing steps to prepare the data for model training.

**Model Training:** Implementation and training of different fraud detection models, including Logistic Regression, Random Forest, Decision Tree, Support Vector Machines (SVM), and Neural Networks.

**Model Evaluation:** Assessing the performance of the models using metrics such as AUC-ROC, precision, recall, F1-Score, and visualizing ROC curves and confusion matrices.

**Choosing the Best Model:** Identifying the model that best suits the specific credit card fraud detection problem based on evaluation metrics.

### Importing Libraries, Loading CSV Data and Visualizing Data
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

file_path = "/kaggle/input/creditcardfraud/creditcard.csv"
df = pd.read_csv(file_path)

df.head()

"""## Checking the data"""

df.shape

df.info()

"""We can see that this dataset has 284,807 records, 31 columns, all of which contain numerical values. The last column ('class') determines whether a transaction is fraudulent or not.

### Checking for null values.
"""

df.isnull().sum()

"""As we can see, there are no null values, which is great.

### Distribution of numerical data
"""

df_num = df.select_dtypes(include = ['float64', 'int64'])
df_num.head()

"""## Now let's plot the distribution of all numerical features."""

df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);

"""## Prepare the dataset

Now let's split the dataset into training and testing sets:
"""

import numpy as np
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=0.3, random_state=42)

print("{} examples for training, {} examples for testing.".format(
    len(X_train), len(X_test)))

"""## Let's create a function to later plot the confusion matrix."""

from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={"size": 16})
    plt.title(f'Confusion Matrix for {model_name}')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

"""### Performs logistic regression using scikit-learn, makes predictions on a test set, and plots the confusion matrix for evaluation"""

from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)
predictions_logreg = logreg.predict(X_test)

plot_confusion_matrix(y_test, predictions_logreg, 'Logistic regression')

"""### Performs Random Forest using scikit-learn, makes predictions on a test set, and plots the confusion matrix for evaluation"""

from sklearn.ensemble import RandomForestClassifier

# Exemplo com Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
predictions_rf = rf.predict(X_test)

plot_confusion_matrix(y_test, predictions_rf, 'Random Forest')

"""### Performs Decision Forest using scikit-learn, makes predictions on a test set, and plots the confusion matrix for evaluation"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
predictions_dt = dt.predict(X_test)

plot_confusion_matrix(y_test, predictions_dt, 'Decision Forest')

"""### Performs SVM using scikit-learn, makes predictions on a test set, and plots the confusion matrix for evaluation"""

from sklearn.svm import SVC

svm = SVC()
svm.fit(X_train, y_train)
predictions_svm = svm.predict(X_test)

plot_confusion_matrix(y_test, predictions_svm, 'SVM')

"""### Performs Neural Networks using scikit-learn, makes predictions on a test set, and plots the confusion matrix for evaluation"""

from sklearn.neural_network import MLPClassifier

# Exemplo com Redes Neurais
nn = MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=1000)  # Exemplo com duas camadas ocultas de 64 neur√¥nios cada
nn.fit(X_train, y_train)
predictions_nn = nn.predict(X_test)

plot_confusion_matrix(y_test, predictions_nn, 'Neural Networks')

"""### Visualizes precision, recall, F1-score, and AUC-ROC metrics for different machine learning models (Logistic Regression, Random Forest, Decision Tree, SVM, Neural Networks)"""

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score

def safe_precision_score(y_true, y_pred):
    if sum(y_pred) == 0:
        return 0.0
    return precision_score(y_true, y_pred)


# Lists to store metrics for each model
models = ['Logistic Regression', 'Random Forest', 'Decision Tree', 'SVM', 'Neural Networks']
precision = [safe_precision_score(y_test, predictions_logreg),
             safe_precision_score(y_test, predictions_rf),
             safe_precision_score(y_test, predictions_dt),
             safe_precision_score(y_test, predictions_svm),
             safe_precision_score(y_test, predictions_nn)]
recall = [recall_score(y_test, predictions_logreg), recall_score(y_test, predictions_rf),
          recall_score(y_test, predictions_dt), recall_score(y_test, predictions_svm),
          recall_score(y_test, predictions_nn)]
f1 = [f1_score(y_test, predictions_logreg), f1_score(y_test, predictions_rf),
      f1_score(y_test, predictions_dt), f1_score(y_test, predictions_svm),
      f1_score(y_test, predictions_nn)]
roc_auc = [roc_auc_score(y_test, predictions_logreg), roc_auc_score(y_test, predictions_rf),
           roc_auc_score(y_test, predictions_dt), roc_auc_score(y_test, predictions_svm),
           roc_auc_score(y_test, predictions_nn)]

# Create a DataFrame for easier visualization
results_df = pd.DataFrame({
    'Model': models,
    'Precision': precision,
    'Recall': recall,
    'F1-Score': f1,
    'AUC-ROC': roc_auc
})


# Plot the results using subplots
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Comparison of Metrics for Different Models')

sns.barplot(ax=axes[0, 0], data=results_df, x='Model', y='Precision', palette='Blues')
axes[0, 0].set_title('Precision')
axes[0, 0].set_ylim(0, 1)  # Adjust according to your max precision values

sns.barplot(ax=axes[0, 1], data=results_df, x='Model', y='Recall', palette='Oranges')
axes[0, 1].set_title('Recall')
axes[0, 1].set_ylim(0, 1)  # Adjust according to your max recall values

sns.barplot(ax=axes[1, 0], data=results_df, x='Model', y='F1-Score', palette='Greens')
axes[1, 0].set_title('F1-Score')
axes[1, 0].set_ylim(0, 1)  # Adjust according to your max F1-Score values

sns.barplot(ax=axes[1, 1], data=results_df, x='Model', y='AUC-ROC', palette='Purples')
axes[1, 1].set_title('AUC-ROC')
axes[1, 1].set_ylim(0, 1)  # Adjust according to your max AUC-ROC values

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

from sklearn.metrics import roc_curve

# Function to plot the ROC Curve
def plot_roc_curve(y_true, y_scores, label):
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc_score(y_true, y_scores):.2f})')

# Add ROC Curves for each model
plot_roc_curve(y_test, logreg.predict_proba(X_test)[:, 1], 'Logistic Regression')
plot_roc_curve(y_test, rf.predict_proba(X_test)[:, 1], 'Random Forest')
plot_roc_curve(y_test, dt.predict_proba(X_test)[:, 1], 'Decision Tree')
plot_roc_curve(y_test, svm.decision_function(X_test), 'SVM')
plot_roc_curve(y_test, nn.predict_proba(X_test)[:, 1], 'Neural Networks')

# Layout adjustments
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('ROC Curve for Fraud Detection Models')
plt.legend()
plt.show()

# DataFrame to store metrics
metrics_df = pd.DataFrame({
    'Model': models,
    'AUC-ROC': roc_auc,
    'Precision': precision,
    'Recall': recall,
    'F1-Score': f1
})

# Display the metrics DataFrame
print(metrics_df)

# Determine the best model based on a specific metric
best_model_auc = metrics_df.loc[metrics_df['AUC-ROC'].idxmax()]
best_model_precision = metrics_df.loc[metrics_df['Precision'].idxmax()]
best_model_recall = metrics_df.loc[metrics_df['Recall'].idxmax()]
best_model_f1 = metrics_df.loc[metrics_df['F1-Score'].idxmax()]

print("\nBest Model (AUC-ROC):")
print(best_model_auc)

print("\nBest Model (Precision):")
print(best_model_precision)

print("\nBest Model (Recall):")
print(best_model_recall)

print("\nBest Model (F1-Score):")
print(best_model_f1)

# Create a bar chart for precision, recall, and F1-Score metrics
plt.figure(figsize=(12, 8))
metrics_df_melted = pd.melt(metrics_df, id_vars='Model', var_name='Metric', value_name='Value')
sns.barplot(data=metrics_df_melted, x='Model', y='Value', hue='Metric', palette='viridis')
plt.title('Comparison of Metrics for Fraud Detection Models')
plt.ylabel('Value')
plt.show()

"""In conclusion, the analysis identifies the Random Forest model as the best performer based on the F1-Score metric. With an AUC-ROC of 0.908053, Precision of 0.948718, Recall of 0.816176, and an F1-Score of 0.87747, the Random Forest model demonstrates a balanced performance across precision and recall, making it a robust choice for the given task.

# If you find this notebook useful, support with an upvote
"""

